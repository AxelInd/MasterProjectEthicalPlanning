\documentclass{article}
\usepackage{graphicx}

\usepackage{amsthm}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section] % reset theorem numbering for each chapter

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition} % definition numbers are dependent on theorem numbers
\newtheorem{exmp}[thm]{Example} % same for example numbers


\begin{document}

\title{HP-Causality in Multi-agent Planning Tasks}
\author{Axel Ind}

\maketitle

\begin{abstract}
HP-Causality (@TODO reference) allows us to determine which variable values are causes of certain other final variable values. The normal HP-Causality approach is limited to a structural equation representations of the problem under consideration. This paper describes a multi-agent planning approach to defining causality. Extensions to the Original, Updated, and Modified definitions of HP-Causality to planning are formalised and discussed.
\end{abstract}

%-----------------------------INTRODUCTION----------------------------------------
\section{Introduction}
@TODOall mention why HP causality is not useful for action plans (single step etc), mention previous work in planning ethics limited to single-agent cases. Mention value of multi-agent planning (i.e. more realistic).

%-----------------------------PRELIMINARIES---------------------------------------
\section{Planning Preliminaries}

\subsection{Single Agent Planning Tasks}
\subsubsection*{Language}
A single-agent planning task is a 4-tuple $\Pi=(V, A, s_0, s_\star)$. Where $V$ denotes the set of variables and maps each to it's allowable values (or domain) such that, for some variable $v$, $v \in D_v$. A \textit{fact} is a pair $(v, d \in D_v)$. A conjunction of facts $v_1=d_1,...,v_k=d_k$ is \textit{consistent} if it contains no contradictory facts. That is, no pair of facts exists in this conjunction such that $v_j=d_j$ and $v_j \neq d_j$.

$A$ denotes the set of \textit{actions} available to the agent. An action $a=<pre,eff>$ consists of a precondition, and an effect. A precondition is a conjunction of facts ($v_1=d_1,...,v_k=d_k$) and an effect is a conjunction of facts in \textit{effect normal form} (@TODOref) of the form $\phi_i \triangleright v_i:=d_i$. No contradictory effects are permitted for a single action. That is no pair of conditionals exists such that $\phi_i \triangleright v_j=d_j$ and $\phi_j \triangleright v_j \neq d_j$. $A$ is divided into two types of actions, endogenous actions and exogenous actions. Intuitively endogenous actions describe those actions an agent is able to choose to take. @TODOref add the requirement that the set of endogenous actions always contains the empty action $\epsilon=(\top,\bot)$, this is not a strict requirement in this paper, but is worth noting as a possible simplifying extension. Exogenous actions describe actions which are outside of the control of the agent and must be performed whenever possible. @TODOref treat exogenous actions as a series of, non-conflicting, actions which are associated with discrete time points $t(a)$ and must be applied as soon as they become applicable and result in a state change. By contrast, this paper drops the requirement that exogenous actions be non-conflicting and instead introduces the permissive and strict approach to dealing with such actions.

The \textit{state} of a classical planning task is the conjunction of all variable pairs. $s_0$ describes the initial state of the agent, before any actions have been performed. $s_\star$ describes the goal state of the agent, to be achieved by execution of some number of consecutive actions.

\subsubsection*{Semantics}
A action $a=<pre, effect>$ is applicable in a state $s$ iff $s\models pre$ @TODOref. For exogenous actions, it is further required that the current state is the $t$-th time state associated with that action. 

The \textit{change set} $[eff]_s$ of an action is the set of facts that are affected by the conditional. specifically $[eff]_s=\cup^k_{i=1}[\phi_i \triangleright v_i:=d_i]$, where $[\phi \triangleright v:=d]_s=\{v=d\}$ if $s \models phi$ and $\emptyset$ otherwise. The change set never contains contradictory facts.

Applying an actions $a$ to state $s$ results a state $s'$ achieved by replacing all variables in $s$ that occur in $[eff]_s$ with conditional values assigned by that change set.

As with @TODOref, we assume \textit{urgent semantics} for exogenous actions. That is, if an exogenous action is applicable, it must be applied immediately and no other action may precede it. However, because this paper allows conflicting exogenous actions, it is not obvious how to deal with cases where multiple exogenous actions are simultaneously applicable. There are three intuitive solutions to this problem:
\begin{enumerate}
\item \textit{Ordering approach}: provide a strict ordering relationship among these actions and always apply the applicable action with the highest precedence first (provided it results in a state change).\footnote{Easy to do, linear time requirements, but forces a possibly unnatural order on events.}
\item \textit{Permissive approach}: select some random order of exogenous actions.\footnote{Linear time requirements, good for generating a plan, but ignores other potential action sequences.}
\item \textit{Strict approach}: consider every possible permutation of exogenous actions that can be performed.\footnote{Exhaustive, but computationally slow.}
\end{enumerate}

This paper will concern itself only with the third approach. $\Delta_{exo}(s)$ refers to the set of unique states that may be achieved by application of all relevant exogenous actions using one of the schemes above (Note that, unlike @TODOref, $\Delta_{exo}(s)$ is not closed and does not guarantee a single unique state in the strict approach).

A \textit{plan} $\pi=(a_1,...a_n)$ is a sequence of endogenous actions. In a typical plan it is sufficient to apply $a_1$ to the initials state $s_0$ to achieve the first state $s_1$ and then apply $a_2$, etc. However, to incorporate exogenous actions, $\Delta_{exo}(s)$ must be calculated at each time point in which an exogenous action may occur. If each action in $\pi$ (supplemented by appropriate intermediate states as a result of $\Delta_{exo}(s)$) is applicable to the preceding state, then the plan is called applicable. 

It is worth noting that using the strict approach to exogenous actions above it does not simply suffice to show that some exogenous action in $\Delta_{exo}(s)$ will make the next endogenous action applicable. Instead all applicable exogenous actions must be considered, thus introducing branching complexity into the computation @TODOintroduceexampleofwhythismatters.



\subsection{Multi-Agent Action Plans and Planning Tasks}
Multi-agent planning tasks extend the intuition of single agent planning tasks as described @TODOsection to allow for consideration of a finite number of agents. Each agent may differ in their allowable actions and goals but are assumed share the same initial state and subsequent states after any endogenous or exogenous action occurs.

A multi-agent planning task $\Xi$ for $n$ agents is a 3-tuple as follows:

\[
\Xi = <A, \Pi, T>
\]

 Where $A=(A_1,...A_k)$ is an ordered list of all agent names in the planning task. $\Pi$ is the ordered list of agent planning tasks for each agent in $A$. $\Pi=(\Pi_1,...,\Pi_n)$, and $T$ is a scheduling function which determines which agents may act at any given time-point $t$.
 
This definition intuitively aggregates a set of disparate planning tasks and makes them accessible via unique labels.

Multi-agent action plans are similar to single-agent action plans, but they also encode information about the agent which performed any given action \footnote{I am aware that this information is trivially obtainable when agent actions have unique names, but I feel that it is more robust to also include explicit labelling information. It allows us, for example, to introduce an arbitrary number of identical new agents to a task without having to change their action labels}. Further, only multi-agent action plans in which the order of agent labels could feasibly be generated by $T$ are considered valid.

A multi-agent action plan $\pi=((A_x, \Pi_x[o]_1),...(A_y, \Pi_y[o]_n))$. Where $A_y$ is the label of the acting agent, and $\Pi_y[o]_n$ describes some applicable operator for agent $y$ at time-point $n$.

For the purposes of readability, the rest of this paper will assume unique operator names and omit agent labels and specification of the operators available for that agent. Thus, multi-agent planning tasks will be treated as $\pi=(o_1,...o_n)$, except where doing so would limit some required expressibility. 

\subsection{Counterfactual Reasoning in Planning}

Counterfactual reasoning concerns the question: ''What would happen if some feature of the world were other than it is?", and is an important part of many approaches to causality @TODOrefhp. For example, we can intuitively grasp concepts such as: ``\textit{if the boy had not done his homework, he would not have passed}", which deal with a world different from the one in which we exist. Thus, without going into the minutia of defining causality, as will be done later, we have some intuition that not doing his homework, may have been cause of his failure.

But this reasoning is simplistic. What if the boy's grades were so bad that he would have failed anyway? Could we still consider not doing his homework to be a cause of failure? Our intuitions of cause differ from scenario to scenario, and for this reason we consider four distinct definitions of causality in this paper.

@TODOref introduce and justify a simple counterfactual reasoning procedure for single-agent plans. Specifically it asks what would have happened if some action had not occured and the agent had instead done nothing? In the context of a planning task the authors note that is not sufficient to replace the action slot pair $(a_j, o_j)$ in question with the empty action $\epsilon=(\top, \bot)$ to make $(a_j, \epsilon)$, because that action may have caused variable assignment $v=d$ and without that assignment some later action $a_{j+k}$ may no longer be permissible. The authors, instead, allow impermissible actions to be considered during counterfactual reasoning. That is, they assume that, provided the plan was initially valid, we should allow all other actions to occur as they had before, regardless of violated preconditions.

For this paper we consider a slightly more robust choice of actions. Instead of introducing the empty action, we consider the full set of applicable actions available to an agent in a given state. In order to concisely capture the minutia of this kind of counterfactual reasoning we borrow intuition from the causality framework of @TODOrefHP and introduce our own framework.

Given a single-agent planning task $\Pi=(V, A, s_0, s_\star)$ and plan $\pi<a_1,...,a_n>$, we define the \textit{causal plan setting} (CPS) $(\pi,\Pi)$. Intuitively the CPS corresponds to the full set of information we have involving the problem. It describes the goal, constraints, and exogenous circumstances that drove the sequence of actions that actually occurred.

Let $s_n$ denote the final state of the agent after each action in the planning task has been applied\footnote{Although we have stated that plans using conflicting exogenous actions do not necessarily result in a single deterministic final state, our intuition for causality allows us to treat the plan and final state as known quantities examined after the fact. Thus we ensure that there is only one state final state $s_n$}. The variable assignment for which we would like to identify the cause $\phi$ is always such that $s_n \models \phi$ in the CPS. The relationship between the $CPS$ and $\phi$ is described as follows:

\[
(\pi, \Pi) \models (s_n \models \phi)
\]

An \textit{action slot} $q(\pi,k)$ denotes the domain of possible actions at a given position. For example, if $\pi=(a_1,a_2,a_3)$, $q(\pi,1)$ identifies the position occupied by $a_1$, thus containing action $a_1$ and any other action that could have been performed by any agent at that moment.

Let $\pi'\mapsto \pi$ denote a situation in which all elements in $\pi'$ are action slots in $\pi$ which could have occurred in the same order or else are the empty action. Specifically, for all $a_k \in \pi'$, $a \in q(\pi,k) \cup \epsilon$. The operation $\pi'\mapsto \pi$ is henceforth abbreviated to the symbol $\pi'$.

$\pi' \leftarrow \vec{o'}$ is the setting of every non-$\epsilon$ action slot $a_k$ to the singleton action $\vec{o'}[k]$.


A counterfactual consideration on a CPS asks the question ``What if some subset of actions $\pi'$ in $\pi$ had been given the values $\vec{o'}$?". If changing the values of $\vec{o'}$ still results in the values $\phi$ in the final state, we write:

\[
(\pi, \Pi) \models [\pi' \leftarrow \vec{o'}](s_n \models \phi)
\]

If, on the other hand, $\phi$ no longer holds in the final state, we write:

\[
(\pi, \Pi) \models [\pi' \leftarrow \vec{o'}](s_n \not\models \phi)
\]


A \textit{multiagent causal plan setting} (MCPS) works in an analogous way. The MCPS $(\pi,\Xi)$ is the multi-agent planning task combined with the executed plan. Actions slots now also encompass allowable actions by other agents at a given timeslot (remember that which agents may act at that time slot is determined by the scheduling function $T$).

A counterfactual consideration on a MCPS in which setting the actions slots described by $\pi'$ to the actions $\vec{o'}$ still results in the values $\phi$ in the final state, we write:

\[
(\pi, \Xi) \models [\pi' \leftarrow \vec{o'}](s_n \models \phi)
\]

And if $\phi$ no longer holds in the final state, we write:

\[
(\pi, \Xi) \models [\pi' \leftarrow \vec{o'}](s_n \not\models \phi)
\]

Finally, let $(\pi-\pi')$ denote the plan obtained by setting all non-$\epsilon$ actions slots in $\pi'$ to $\epsilon$ in $\pi$. For example, given $\pi=(a_1,a_2,a_3)$ and $\pi'=(\epsilon, a_2, \epsilon)$, $(\pi-\pi')=(a_1, \epsilon, a_3)$, where $a_i$ is an action slot.

\section{Mathematical Preliminaries HP Causality}

@TODOall  Discuss the idea of causes. Provide details about the causal setting. Discuss counterfactual reasoning.

Halpern and Pearl @TODOref set out to define the cause of variable assignments in the final world. In order to do this they required a rigid and consistent set of operations on representations of the real world.

The first step in the HP approach is to define the \textit{model}. Using this model, it is possible to make statements such as ``$A$ is the cause of $B$ in  model $M$ according to some definition of causality $X$." Though we might disagree on precisely which definition of causality to use, we should still achieve unambiguous solutions when that definition is applied. 

A model makes use of set of \textit{variables} which may take on various values. In our running example, the boy doing his homework may be a variable $HW$ where $HW=1$ may denote the boy doing his homework and $HW=0$ denotes that he has not done his homework. The concept of variables in HP-causality is analogous to that which we have described in planning. However, in HP-causality there is no separation of actions from variables. Thus, as well as having discrete values assigned \textit{a priori}, variable assignments can also occur as the result of \textit{structural equations}. When all variable domains are binary ($X \in \{0,1\}$), any structural equations can be expressed as $X=\phi$ where

\[
\phi= \phi | \phi' | max(\phi, \phi') | min(\phi, \phi') 
\]

Intuitively the $max()$ and $min()$ operations capture the $\land$ and $\lor$ operations defined in planning, respectively. And, indeed, the same symbols are often used in HP-causality models.

Halpern and Pearl define \textit{exogenous variables} and \textit{endogenous variable}. Exogenous variables are those variables whose value is determined by factors outside the model. Endogenous variables, by contrast, are defined by structural equations within the model.

Halpern and Pearl enforce an independence criteria on structural equations, so that the sequence in which that are considered does not matter and the final variable assignments are still deterministically defined. To evaluate a causality model, one first assigns the exogenous variables, and then iterates through the structural equation (updating variables at each step) until no new variable assignments occur (@TODOdiagram).

A causal setting $(M,u)$ is the world described by the structural equations of the model $M$ and the exogenous variables $u$. For a given set of variables $phi$ the causal setting exactly describes the value of all those variables after calculation of all structural equations. We write

\[
(M,u) \models \phi
\]

The final information needed to describe causality in causal settings is a way to represent counterfactual reasoning. To represent the idea of ``What would happen if some feature of the world were other than it is", we use variable alternate variable assignments $x'$ for some set of variables $X$. Thus, if changing $X$ to $x'$ prime still results in variable assignments $\phi$ we write

\[
(M,u)\models [X\leftarrow x']\phi
\]

And if $\phi$ no longer holds after the assignment we write

\[
(M,u)\models [X\leftarrow x']\lnot \phi
\]

%-----------------------------HP CAUSALITY----------------------------------------
\section{HP-Causality}
This section briefly describes the notion of HP-causality and the three main definitions. @TODO must include 2 other definition and description of how inserting counterfactuals works.


\subsection{The Original definition of HP-Causality}
\begin{defn}$X=x$ is an actual cause of $\phi$ in the causal setting $(M,u)$ according to the original causality definition iff the following 3 conditions hold:
\begin{enumerate}
\item $(M,u) \models (X=x)$ and $(M,u) \models \phi$.
\item $AC2(a)$: There is a partition of $V$ (the endogenous variables) into two disjoint subsets $Z$ and $W$ with $X'\subseteq Z'$ and a setting $x'$ and $w$ of the variables in $X$ and $W$, respectively, such that

\[
(M,u) \models [X\leftarrow x', W\leftarrow w]\lnot \phi
\] 

\item $AC2(b^o)$: If $z^\star$ is such that $(M,u)\models Z = z^\star$, then for all subsets $Z'$ of $Z-X$, we have

\[
(M,u) \models [X\leftarrow x, W \leftarrow w, Z' \leftarrow z^\star]\phi
\] 

\item $X$ is minimal, there is no strict subset of $X'$ of $X$ such that $X' = x'$ satisfies the above conditions.
\end{enumerate}

\end{defn}

\subsection{The Updated definition of HP-Causality}
\begin{defn}$X=x$ is an actual cause of $\phi$ in the causal setting $(M,u)$ according to the updated causality definition iff the following 3 conditions hold:
\begin{enumerate}
\item $(M,u) \models (X=x)$ and $(M,u) \models \phi$.
\item $AC2(a)$: There is a partition of $V$ (the endogenous variables) into two disjoint subsets $Z$ and $W$ with $X'\subseteq Z'$ and a setting $x'$ and $w$ of the variables in $X$ and $W$, respectively, such that

\[
(M,u) \models [X\leftarrow x', W\leftarrow w]\lnot \phi
\] 

\item $AC2(b^u)$: If $z^\star$ is such that $(M,u)\models Z = z^\star$, then for all subsets $Z'$ of $Z-X$ and $W'$ of $W$, we have

\[
(M,u) \models [X\leftarrow x, W' \leftarrow w, Z' \leftarrow z^\star]\phi
\] 

\item $X$ is minimal, there is no strict subset of $X'$ of $X$ such that $X' = x'$ satisfies the above conditions.
\end{enumerate}

\end{defn}













\subsection{The Modified definition of HP-Causality}
\begin{defn}$X=x$ is an actual cause of $\phi$ in the causal setting $(M,u)$ iff the following 3 conditions hold:
\begin{enumerate}
\item $(M,u) \models (X=x)$ and $(M,u) \models \phi$.
\item $AC2(a^m)$: There is a set $\vec{W}$ of variables in $V$ and a setting $x'$ of the variables in $X$ such that if $(M,u) \models W = w^*$, then:
\[
(M,u) \models [X \leftarrow x', W \leftarrow w^*] \neg \phi
\]
\item $X$ is minimal. There is no strict subset of $X$ that satisfies the previous 2 conditions.
\end{enumerate}

\end{defn}

Intuitively the first two requirements are: the possible cause must actually have occurred, the final variable assignment under consideration must also have occurred; and changing the possible cause and fixing some number of other variable assignments can change the final variable assignment under consideration.




\newpage

\section{HP-Causality Planning}
The HP causality definitions above are restricted to the identification of variable causes, and as such, are not suitable for use in a planning domain where questions posed may also require the identification of a subset of actions or agents as causes.

For this reasons I propose changed definitions of the HP-causality models which produce comparable conclusions given intuitively identical, but structural different problems. Specifically, my definitions allow for the use of actions plans rather than structural equations as original used.

\subsection{But-for Causality Planning}

\subsection{HP-Causality Modified Planning}

\subsubsection*{But-for Planning}
\begin{defn} 

Given a multi-agent action plan $\pi$ with a final state $s_n$, some ordered subset of the actions in $\pi$, $\pi' \mapsto \pi$, $\pi' \leftarrow o$ is a but-for cause of some final variable assignment $s_n \models \phi$ iff the following 3 conditions hold:
\begin{enumerate}
\item  $o \mapsto \pi$, $\pi' \models o$ and $s_n \models \phi$.
\item $BF2$: There is a setting $\vec{o'}$ of the non-$\epsilon$ action slots in $\pi'$ such that:
\[
(\pi, \Xi) \models [\pi' \leftarrow o'](s_n \not\models \phi)
\]
\item $\pi'$ is minimal. There is no strict subset of $\pi'$ that satisfies the previous 2 conditions.
\end{enumerate}


\end{defn}

\subsubsection*{Original Planning}
\begin{defn}
Given a multi-agent action plan $\pi$ with a final state $s_n$, some ordered subset of the actions in $\pi$, $\pi' \mapsto \pi$, $\pi' \leftarrow o$ is a cause of some final variable assignment $s_n \models \phi$ according to the Original planning definition iff the following 3 conditions hold:
\begin{enumerate}
\item  $o \mapsto \pi$, $\pi' \models o$ and $s_n \models \phi$.



\item $BF2(a)$: There is a partition of $E$ (the \textit{endogenous} actions) into two disjoint subplans $Z \mapsto \pi$ and $W \mapsto (\pi - Z)$ with $\pi' \mapsto Z$ and a setting $o'$ and $w'$ of the actions in $\pi'$ and $W$ respectively such that

\[
(\pi, \Xi) \models [\pi' \leftarrow o', W \leftarrow w'](s_n \not\models \phi)
\]

\item $BF2(b^o)$: If $z^\star$ is such that $(\pi, \Xi) \models Z = z^\star$, then for all subplans $Z' \mapsto (Z - \pi')$ we have

\[
(\pi, \Xi) \models [\pi \leftarrow o, W \leftarrow w', Z' \leftarrow z^\star](s_n \models \phi)
\]

\item $\pi'$ is minimal. There is no strict subset of $\pi'$ that satisfies the previous 3 conditions.
\end{enumerate}
\end{defn}

(Where $Z\leftarrow z^\star$ denotes fixing all non-$\epsilon$ action slots in $Z$ to their original actions.)



\subsubsection*{Updated Planning}
\begin{defn}
Given a multi-agent action plan $\pi$ with a final state $s_n$, some ordered subset of the actions in $\pi$, $\pi' \mapsto \pi$, $\pi' \leftarrow o$ is a cause of some final variable assignment $s_n \models \phi$ according to the Original planning definition iff the following 3 conditions hold:
\begin{enumerate}
\item  $o \mapsto \pi$, $\pi' \models o$ and $s_n \models \phi$.



\item $BF2(a)$: There is partition of $E$ (the endogenous actions) into two disjoint subplans $Z \mapsto \pi$ and $W \mapsto (\pi - Z)$ with $\pi' \mapsto Z$ and a setting $o'$ and $w'$ of the actions in $\pi$ and $W$ respectively such that

\[
(\pi, \Xi) \models [\pi' \leftarrow o', W \leftarrow w'](s_n \not\models \phi)
\]

\item $BF2(b^u)$: If $z^\star$ is such that $(\pi, \Xi) \models Z = z^\star$, then \textit{for all} subplans $W' \mapsto W$ and $Z' \mapsto (Z - \pi')$ we have

\[
(\pi, \Xi) \models [\pi \leftarrow o, W' \leftarrow w', Z \leftarrow z^\star](s_n \models \phi)
\]

\item $\pi'$ is minimal. There is no strict subset of $\pi'$ that satisfies the previous 3 conditions.
\end{enumerate}
\end{defn}

(Where $Z\leftarrow z^\star$ denotes fixing all non-$\epsilon$ action slots in $W$ to their original actions.)

\subsubsection*{Modified Planning}
\begin{defn}
Given a multi-agent action plan $\pi$ with a final state $s_n$, some ordered subset of the actions in $\pi$, $\pi' \mapsto \pi$, $\pi' \leftarrow \vec{o}$ is a cause of some final variable assignment $s_n \models \phi$ according to the modified planning definition iff the following 3 conditions hold:
\begin{enumerate}
\item  $\vec{o} \mapsto \pi$, $\pi' \models \vec{o}$ and $s_n \models \phi$.
\item $BF2$: There is a setting $\vec{o'}$ of the applicable actions in $\vec{\pi'}$, and a setting of $W \mapsto (\pi  - \pi')$ such that:
\[
(\pi, \Xi) \models [\pi' \leftarrow \vec{o'}, W \leftarrow \vec{w^\star}](s_n \not\models \phi)
\]
\item $\pi'$ is minimal. There is no strict subset of $\pi'$ that satisfies the previous 2 conditions.
\end{enumerate}


(Where $W\leftarrow \vec{w^\star}$ denotes fixing all non-$\epsilon$ action slots in $Z$ to their original actions.)

\end{defn}

\subsubsection*{Agent Causes}
Sometimes we may desire to know if a specific agent or subset of agents caused a particular variable assignment to occur. This allows for statements such as ``Person $X$ is solely responsible for event $\phi$".
\begin{defn}
A subset of agents $\vec{A}$ is a cause of $\phi$ iff there exists some cause $\vec{X}=\vec{x}$ of $\phi$ such that every agent in $\vec{A}$ is a label of at least one action in $\vec{X}$, further, only agents mentioned in $\vec{A}$ are action labels in $\vec{X}$.
\end{defn}



\subsubsection*{Notes on the above definitions}
\begin{itemize}
\item These definitions are strictly more inclusive than but-for cause checks. This is because when $\vec{W}=\{\}$, the $MC2(a^m)$ precisely models but-for causes (under minimality requirements for the but-for cause).
\item The action plan obtained by replacing certain actions may no longer be valid. Much like in the normal HP definition of causality, where impossible variable assignments can be fixed during counter-factual reasoning.
\item The most significant remaining concern relates to the treatment of exogenous events. Using a single exogenous event for all non-agent actions makes it very difficult to properly assign causality due to problems it causes with fixing variables. This will be detailed in the next section.
\item One might wonder why my definitions do not refer to fixing variables at all, and only focus on actions. I have no strong argument for this decision except the observations that fixing some variable $X=x$ can be done in constant time by the inclusion of an action $s=(\top,X=x)$ in the action plan. This action can then be fixed. This addition can be done in $O(|X|)$ time.
\end{itemize}



\iffalse
\subsection{Planning Causality relations}

The following table shows which classes causes my definition of causality can identify. Columns are results $\phi$. Rows are causes $\vec{X}$.

\begin{center}
\begin{tabular}{ |c|c|c| }
\hline 
  & \textbf{Variable} & \textbf{Action} \\
 \hline 
 \textbf{Variable} & No\footnote{Although it has been mentioned that actions can be used to fix variables. Which gives the same results one would intuitively expect when using variables.} & No \\ 
 \hline
 \textbf{Action} & Yes & @TODO \\ 
 \hline
 \textbf{Agent} & Yes & @TODO\\
 \hline
\end{tabular}
\end{center}

@TODO I would like to address the following questions:

\begin{enumerate}
\item What does it mean for an action to be the cause of an action? Is it sufficient to say that without that prior action the next action would not have occurred? What if only one action was available so $X=x'=x$?
\item How would extensions to a game theory approach affect causality? What if changing some action $X$ would always result in a known change to some later action $Y$? Would we treat the two actions as a single action for the purposes of fixing and changing actions? How would this affect computational complexity?
\end{enumerate}



\section{Responsibility and Blameworthiness}
\subsection{HP Responsibility and Blameworthiness}
\subsection{Extending Responsibility and Blameworthiness to Planning}

\fi

\section{Examples}

\section{Conclusion}
\end{document}